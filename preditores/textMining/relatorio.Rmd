---
title: "Categorização das respostas Pontos Frageis e Fortes"
author: "Henrique Pinto Gomide"
date: "20-08-2014"
output: html_document
toc: yes
---

# Introdução

Este é o resumo das análises para facilitar a categorização. Siga o sumário acima. Separei o documento em duas grandes estruturas:

1. Pontos frageis
2. Pontos fortes

Dentro de cada grande estrutura, você deverá ver as análises separadas entre radicais e palavras completas. Lembre-se das vantagens e desvantagens de cada um que discutimos.

Ao final, a parte mais difícil. Você precisará ter calma e identificar quais as palavras estão mais correlacionadas. Eu deixei ao final do documento para não afastar as partes anteriores com muito texto.

Não se esqueça de ir criando possíveis categorias durante as análises e de conferir sua validade com o arquivo em planilha.

Boa sorte e bom trabalho,

:)

```{r, echo = FALSE, warning=FALSE, results='hide', message=FALSE}
# Loading Libraries
library("tm")
library("SnowballC")
library("Rgraphviz")
library("wordcloud")
library("RColorBrewer")
library("ggplot2")
library("xtable")

# Import data file ----
capa  <- read.table("categorizacao.csv", header = T, fill=TRUE, sep=",")
capa  <- capa[,-c(3,4)]
```


# Pontos Fracos

```{r, echo=FALSE}
# Weak points ----

# Define Corpus
corpusWeak  <- VCorpus(VectorSource(capa$pontosfrageis))

# Remove blank spaces, transforming to Lower, remove punctuation, remove stopwords and stem doc.
corpusWeak  <- tm_map(corpusWeak, content_transformer(stripWhitespace))
corpusWeak  <- tm_map(corpusWeak, content_transformer(tolower))
corpusWeak  <- tm_map(corpusWeak, content_transformer(removePunctuation))
corpusWeak  <- tm_map(corpusWeak, content_transformer(removeNumbers))
corpusWeak  <- tm_map(corpusWeak, removeWords, stopwords("portuguese"))
corpusWeakS  <- tm_map(corpusWeak, stemDocument, "portuguese")

# Inspect corpusFrageis
dtmWeak <- TermDocumentMatrix(corpusWeak)
dtmWeakS <- TermDocumentMatrix(corpusWeakS)

```


## Palavras

Estas são as palavras mais frequentes (com mais de 200 ocorrências):

```{r echo=FALSE}
# Find frequent words
findFreqTerms(dtmWeak, lowfreq =200)
freqWordsWeak  <- findFreqTerms(dtmWeak, lowfreq =200)

```


### Gráfico de correlação entre as palavras

```{r}
plot(dtmWeak, terms = findFreqTerms(dtmWeak, lowfreq= 300), corThreshold=.3)
```


### Clusters

Este é o resultado da análise de Clusters

```{r, echo=FALSE, results='hide'}
dtm2Weak <- removeSparseTerms(dtmWeak, sparse=0.90)
# convert the sparse term-document matrix to a standard data frame
mydataWeak <- as.data.frame(inspect(dtm2Weak))

```


```{r, echo = TRUE, fig.height=7}
# Scale
mydata.df.scale <- scale(mydataWeak)
d <- dist(mydata.df.scale, method = "euclidean") # distance matrix
fitA <- hclust(d, method="ward.D")
plot(fitA, main="") # display dendogram
```


## Radicais

Nesta sessão, são descritas as análises feitas com os radicais das palavras.



### Frequência

```{r echo=FALSE}
# Find frequent words
findFreqTerms(dtmWeakS, lowfreq =200)
freqWordsWeakS  <- findFreqTerms(dtmWeakS, lowfreq =200)
```


### Gráfico de correlação entre os radicais

```{r}
plot(dtmWeakS, terms = findFreqTerms(dtmWeakS, lowfreq= 300), corThreshold=.3)
```

## Clusters

```{r, echo=FALSE, results='hide'}
dtm2WeakS <- removeSparseTerms(dtmWeakS, sparse=0.90)
# convert the sparse term-document matrix to a standard data frame
mydata.df <- as.data.frame(inspect(dtm2WeakS))
# Scale
mydata.df.scale <- scale(mydata.df)
d <- dist(mydata.df.scale, method = "euclidean") # distance matrix
fitB <- hclust(d, method="ward.D")
```


```{r, echo = TRUE, fig.height=7}
plot(fitB, main="") # display dendogram
```


# Pontos Fortes

```{r, echo=FALSE}
# Weak points ----

#definindo corpus
corpusStrong  <- VCorpus(VectorSource(capa$pontosfortes))

#removendo espaços em branco, formatando as letras em minúsculas e removendo a pontuação
corpusStrong  <- tm_map(corpusStrong, content_transformer(stripWhitespace))
corpusStrong  <- tm_map(corpusStrong, content_transformer(tolower))
corpusStrong  <- tm_map(corpusStrong, content_transformer(removePunctuation))
corpusStrong  <- tm_map(corpusStrong, content_transformer(removeNumbers))
corpusStrong  <- tm_map(corpusStrong, removeWords, stopwords("portuguese"))
corpusStrongS  <- tm_map(corpusStrong, stemDocument, "portuguese")

# Inspect corpusFrageis
dtmStrong <- TermDocumentMatrix(corpusStrong)
dtmStrongS <- TermDocumentMatrix(corpusStrongS)

```


## Palavras

Estas são as palavras mais frequentes (com mais de 200 ocorrências):

```{r echo=FALSE}
# Find frequent words
findFreqTerms(dtmStrong, lowfreq =200)
freqWordsStrong  <- findFreqTerms(dtmStrong, lowfreq =200)

```


### Gráfico de correlação entre as palavras

```{r}
plot(dtmStrong, terms = findFreqTerms(dtmStrong, lowfreq= 300), corThreshold=.3)
```


### Clusters

Este é o resultado da análise de Clusters

```{r, echo=FALSE, results='hide'}
dtm2Strong <- removeSparseTerms(dtmStrong, sparse=0.90)
# convert the sparse term-document matrix to a standard data frame
mydata.df <- as.data.frame(inspect(dtm2Strong))
# Scale
mydata.df.scale <- scale(mydata.df)
d <- dist(mydata.df.scale, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward.D")
```


```{r, echo = TRUE, fig.height=7}
plot(fit, main="") # display dendogram
```


## Radicais

Nesta sessão, são descritas as análises feitas com os radicais das palavras.


### Frequência

```{r, echo=FALSE}
# Find frequent words
findFreqTerms(dtmStrongS, lowfreq =200)
freqWordsStrongS  <- findFreqTerms(dtmStrongS, lowfreq =200)
```


### Gráfico de correlação entre os radicais

```{r}
plot(dtmStrongS, terms = findFreqTerms(dtmStrongS, lowfreq= 300), corThreshold=.3)
```

## Clusters

```{r, echo=FALSE, results='hide'}
dtm2StrongS <- removeSparseTerms(dtmStrongS, sparse=0.90)
# convert the sparse term-document matrix to a standard data frame
mydata.df <- as.data.frame(inspect(dtm2StrongS))
# Scale
mydata.df.scale <- scale(mydata.df)
d <- dist(mydata.df.scale, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward.D")
```


```{r, echo = TRUE, fig.height=7}
plot(fit, main="") # display dendogram
```


# Correlações entre os termos e palavras

## Pontos Frageis

### Correlação entre os radicais mais frequentes

```{r, echo=TRUE}
for (i in 1:length(freqWordsWeakS)) {  
  word  <- freqWordsWeakS[i]
  termo  <- findAssocs(dtmWeakS, word, corlimit=0.3)  
  print(termo)
}
```

### Correlação entre as palavras mais frequentes

```{r, echo=TRUE}
for (i in 1:length(freqWordsWeak)) {  
  word  <- freqWordsWeak[i]
  termo  <- findAssocs(dtmWeak, word, corlimit=0.3)
  print(termo)
}
```

## Pontos Fortes

### Correlação entre os radicais mais frequentes
```{r echo=TRUE}
for (i in 1:length(freqWordsStrongS)) {  
  word  <- freqWordsStrongS[i]
  termo  <- findAssocs(dtmStrongS, word, corlimit=0.3)
  print(termo)
}
```

### Correlação entre as palavras mais frequentes

```{r echo=TRUE}
for (i in 1:length(freqWordsStrong)) {  
  word  <- freqWordsStrong[i]
  termo  <- findAssocs(dtmStrong, word, corlimit=0.3)
  print(termo)
}
```
