---
title: "Artigo 1- Análise de componentes principais e Análise fatorial"
author: "Guilherme, Jéssica e Hrnqieu"
date: "08-24-2015"
output:
  html_document:
    highlight: tango
    number_sections: yes
    theme: spacelab
    toc: yes
---

# Introdução

Este relatório contém as análises introdutória do artigo "Escala de práticas na prevenção do uso de álcool e outras drogas", que está em fase de desenvolvimento pelo [Centro de Referência em Pesquisa, Intervenção e Avaliação em Álcool e Outras Drogas](http://www.ufjf.br/crepeia/).

O objetivo da pesquisa é oferecer uma medida confiável para avaliação das crenças e práticas de educadores de um curso à distância oferecido pela Secretaria Nacional de Políticas sobre Drogas para aproximadamente 10.000 educadores dos estados de Minas Gerais, Rio de Janeiro e Paraná.

Durante todo o processo de desenvolvimento, foram utilizadas ferramentas de código-aberto, para facilitar o re-uso das técnicas e procedimentos desenvolvidos. Todo conteúdo do instrumento e de suas etapas estará disponível para o público no repositório (http://github.com/crepeia/ead-senad). Atualmente, o projeto está hospedado no repositório (http://github.com/henriquepgomide/ead-senad). 

Neste relatório são apresentadas, análises da escala com base em uma amostra de 136 educadores-tutores do curso. As análises foram conduzidas através da linguagem de programação R usando os pacotes *car* e *psych*. 

* R Core Team (2014). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL http://www.R-project.org/.

* John Fox and Sanford Weisberg (2011). An {R} Companion to Applied Regression, Second Edition. Thousand Oaks CA: Sage. URL: http://socserv.socsci.mcmaster.ca/jfox/Books/Companion

* Revelle, W. (2014) psych: Procedures for Personality and Psychological Research, Northwestern University, Evanston, Illinois, USA, http://CRAN.R-project.org/package=psych Version = 1.4.8.



## Banco de Dados

O banco de dados da pesquisa, pode ser obtido no seguinte endereço: (https://github.com/crepeia/ead-senad/blob/master/praticas-profissionais/piloto/praticasprofissionais_df.csv).

Resultados
-------------------------

Os resultados são apresentados por tópicos: caracterização da amostra, avaliação descritiva da escala e análise fatorial exploratória.


### Bibliotecas
```{r}
library(car) # Function Recode
library(psych) # Function Describe
library(ggplot2) # Fancy Charts

## Import dataframe
praticasPro  <- read.csv("piloto/praticasprofissionais_df.csv")

## Sum scales to remove NA's
praticasPro$scaleSum  <- rowSums(praticasPro[,21:63])

## Subset completed observations and consented participation
praticasPro  <- subset(praticasPro, subset=praticasPro$termo=="Sim" & !is.na(praticasPro$scaleSum))
```

### Sócio-demográficas

#### Idade
```{r}
## Age
### Clean data
praticasPro$idade  <- as.numeric(as.character(praticasPro$idade))
praticasPro$idade[praticasPro$idade < 18 | praticasPro$idade > 68 ]  <- NA
### Descriptives
summary(praticasPro$idade) # all
by(praticasPro$idade, praticasPro$sexo, describe) #by sex

```


### Análise Preliminar

```{r}
fullScale  <- praticasPro[,21:63]
# descriptives
describe(fullScale)

## KMO
KMO(fullScale)

# Barlett test of homogeneity
bartlett.test(fullScale)

# Defining factors
auto  <- fa.parallel(fullScale, fm="minres", fa="both", ylabel="Eigenvalues") # yields 4 factors

```

# Figura 1 - Artigo - Scree Plot
```{r echo = FALSE }
# Parallel Analysis
faParalel  <- fa.parallel(fullScale, fm="minres", fa="fa", ylabel="Eigenvalues")
# Create dataframe
screePlot <- data.frame(n = 1:43, fa = auto$pc.values, sim = auto$pc.sim)
# Select just the first 10 factors
screePlot <- screePlot[1:10,]

## Create ggplot ScreePlot
ggplot(screePlot, aes(y = fa, x=1:10, color ="Dados")) + geom_line(linetype = 1) + xlim(1,10) + geom_line(aes(y = screePlot$sim, color = "1"), linetype=4) + theme_bw() + xlab("Fatores") + ylab("Autovalores") + theme(legend.position=c(.85,.80), legend.title = element_text(size = 14), legend.text = element_text(size = 12), axis.title =element_text(size = 12)) + scale_colour_discrete(name = "Legenda", labels=c("Dados simulados","Dados da amostra")) + scale_x_continuous(breaks=c(1,3,5,7,9))

```




```{r echo=FALSE}
# Diagram
fa.diagram(fav1)
```



### Análise de componentes principais com sem rotação / com rotação oblimin
#### 1 Tentativa

```{r}

## Reverse code items according to Theory - I commented this line. The loop is originally from other script.
#for (i in c(14,19,28,29,32,33,34,35)) {
#  aScale[,i] <- recode(aScale[,i], "1=5;2=4;4=2;5=1")
#}

###########################
# EFA
###########################

# FIRST EFA --------
# Factor analysis using polychoric correlations
polyAll <- polychoric(fullScale)

# Unrotated PCA
faAll <- principal(polyAll$rho, nfactors = 2)
print.psych(faAll, digits=2, cut= .4)

# Rotated PCA
faAll_rot <- principal(polyAll$rho, nfactors = 2, rotate="oblimin")
print.psych(faAll_rot, digits=2, cut= .4)
# Results - Items 03,08,15,21,31,26,41 need to be removed due to small loadings < (.4).

```


#### 2 Tentativa sem rotação / com rotação oblimin

```{r}
# SECOND EFA -------
# Remove items with low loadings detected in previous step.
shortScale  <- fullScale[, -c(3,8,15,21,31,36,41)]
polyShort <- polychoric(shortScale)
# Unrotated PCA
faShortScale <- principal(polyShort$rho, nfactors = 2)
print.psych(faShortScale, digits=2, cut= .4)
# Rotated PCA
faShortScale_rot <- principal(polyShort$rho, nfactors = 2, rotate="oblimin")
print.psych(faShortScale_rot, digits=2, cut= .4)
```

### Alfa de Cronbach
```{r}
factorOne <- shortScale[, c("pp001", "pp002", "pp004", "pp005", "pp006", "pp007", "pp009", "pp010", "pp016", "pp020", "pp026", "pp027", "pp028", "pp032", "pp038", "pp039", "pp043")]
factorTwo <- shortScale[, c("pp011", "pp012", "pp013", "pp014", "pp017", "pp018", "pp019", "pp022", "pp023", "pp024", "pp025", "pp029", "pp030", "pp033", "pp034", "pp035", "pp037", "pp040", "pp042")]
```



### NAO USADO NO ARTIGO ---
### Análise Fatorial com método de fatoração dos mínimos resíduos e rotação oblimin.

```{r}
# Factor Analysis using polychoric correlations
faAll <- fa.poly(fullScale, nfactors = 2, rotate = "oblimin", fm="minres")
print.psych(faAll, digits=2, cut= .3)


## V1 - Items with good loadings ----
# V1 - Version - In this version, I removed items with loadings lower than .4. The proportion of explained variance is 40%. The Cronbach's alpha was 0.90 (CI_95 = .87 - .93); factor 1 alpha's = 0.86, factor 2 alpha's =  0.89. Item pp007 should be evaluated because it is skewed.
v1Scale  <- subset(fullScale, select = -c(3,8,11,13,15,17,21,31,34,36,41))

# Factor analysis using polychoric correlations
fav1 <- fa.poly(v1Scale, nfactors = 2, rotate = "oblimin", fm="minres")
print.psych(fav1, digits=2, cut=0.4, sort = TRUE)

# Cronbach's alpha
alpha(v1Scale, check.keys = TRUE)

alpha(v1Scale[,c("pp007", "pp005", "pp004", "pp016", "pp020", "pp027","pp043", "pp002","pp009","pp006","pp032","pp039","pp010","pp026", "pp001","pp028","pp038")], check.keys = TRUE)

alpha(v1Scale[,c("pp019", "pp030", "pp022", "pp014", "pp012", "pp024","pp033", "pp035","pp025","pp023","pp018","pp040","pp037","pp042", "pp029")], check.keys = TRUE)


# V2 - Version - This must be discussed with Jéssica. In this version, I removed items with loadings lower than .6, which reduced the number of items to 17. The proportion of explained variance is 48%. The alpha was .86. The correlation between factors was .44.
v2Scale <- subset(fullScale, select = c(7,5,4,16,20,27,43,2,9,6,19,30,22,14,12,24,33))

fav2 <- fa.poly(v2Scale, nfactors = 2, rotate = "oblimin", fm="minres")
print.psych(fav2, digits=2, sort = TRUE)
```


